{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.options.display.max_columns = 9999\n",
    "pd.options.display.max_rows = 9999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wals = pd.read_csv('data/wals_language_withstatus.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter columns\n",
    "wals = wals.drop(['iso_code', 'glottocode', 'Name', 'latitude', 'longitude', 'genus', 'family', 'macroarea', 'countrycodes'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter features < 10\n",
    "count_features = wals.shape[0] - wals.isnull().sum()\n",
    "count_features = count_features[count_features > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wals = wals[count_features.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter registers < 10\n",
    "#count_langs = wals.shape[1] - wals.isnull().sum(axis=1)\n",
    "#count_langs = count_langs[count_langs > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wals = wals.iloc[count_langs.index].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wals_target = wals['Status from Glotto']\n",
    "wals = wals.drop('Status from Glotto', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_row(row):\n",
    "    row_wo_nan = row.drop('nan')\n",
    "    if row['nan']:\n",
    "        return pd.Series(np.array([np.nan for i in range(len(row_wo_nan))]), index=row_wo_nan.index)\n",
    "    else:\n",
    "        return row_wo_nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [03:24<00:00,  1.12s/it]\n"
     ]
    }
   ],
   "source": [
    "cols_null = {}\n",
    "for col in tqdm(wals.drop('wals_code', axis=1).columns):\n",
    "    cols_null[col] = len(wals[col].value_counts())\n",
    "    if cols_null[col] > 2:\n",
    "        wals[col] = wals[col].astype(str)\n",
    "        wals[col] = wals[col].fillna('nan')\n",
    "        wals_dummies = pd.get_dummies(wals[col])\n",
    "        wals_dummies = wals_dummies.apply(lambda row: change_row(row), axis=1)\n",
    "        wals_dummies.columns = col + wals_dummies.columns\n",
    "\n",
    "        wals = wals.drop(col, axis=1)\n",
    "        wals = pd.concat((wals, wals_dummies), axis=1)\n",
    "    else:\n",
    "        wals[col] = wals[col].replace({c:ix for ix, c in enumerate(wals[col].value_counts().index)})\n",
    "        wals[col] = wals[col].replace('nan', np.nan)\n",
    "wals.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wals.fillna(-1, inplace=True)\n",
    "wals = wals.loc[wals.wals_code != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wals_melt = pd.melt(wals, id_vars=['wals_code'], var_name='col_name', value_name='feature')\n",
    "wals_ratings = wals_melt[wals_melt.feature != -1]\n",
    "wals_ratings_null = wals_melt[wals_melt.feature == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.2964  0.2953  0.2922  0.2947  0.2954  0.2948  0.0014  \n",
      "MAE (testset)     0.1847  0.1836  0.1822  0.1832  0.1843  0.1836  0.0009  \n",
      "Fit time          13.67   13.86   13.76   13.68   13.68   13.73   0.07    \n",
      "Test time         0.76    0.56    0.74    0.56    0.57    0.64    0.09    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.29637894, 0.2952556 , 0.29216696, 0.29470912, 0.29538527]),\n",
       " 'test_mae': array([0.1847497 , 0.18356322, 0.18223561, 0.18316787, 0.1842871 ]),\n",
       " 'fit_time': (13.6653470993042,\n",
       "  13.863105297088623,\n",
       "  13.764633178710938,\n",
       "  13.681365966796875,\n",
       "  13.679088115692139),\n",
       " 'test_time': (0.7569980621337891,\n",
       "  0.5628390312194824,\n",
       "  0.743659257888794,\n",
       "  0.5637426376342773,\n",
       "  0.5658504962921143)}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = Reader(rating_scale=(0, 1))\n",
    "data = Dataset.load_from_df(wals_ratings, reader)\n",
    "algo = SVD()\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.2910  0.2926  0.2933  0.2935  0.2923  0.2925  0.0009  \n",
      "MAE (testset)     0.1820  0.1829  0.1834  0.1837  0.1821  0.1828  0.0007  \n",
      "Fit time          23.83   23.98   23.98   24.06   24.04   23.98   0.08    \n",
      "Test time         0.54    0.66    0.66    0.54    0.66    0.61    0.06    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.29098244, 0.29256216, 0.29332159, 0.29353345, 0.29228499]),\n",
       " 'test_mae': array([0.1819853 , 0.18285044, 0.1833571 , 0.18366228, 0.1821244 ]),\n",
       " 'fit_time': (23.828102827072144,\n",
       "  23.978682041168213,\n",
       "  23.980900764465332,\n",
       "  24.05958580970764,\n",
       "  24.037503480911255),\n",
       " 'test_time': (0.5368878841400146,\n",
       "  0.6589217185974121,\n",
       "  0.6553318500518799,\n",
       "  0.5382833480834961,\n",
       "  0.6560063362121582)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = Reader(rating_scale=(0, 1))\n",
    "data = Dataset.load_from_df(wals_ratings, reader)\n",
    "algo = SVD(n_factors=200)\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.2903  0.2906  0.2914  0.2900  0.2913  0.2907  0.0005  \n",
      "MAE (testset)     0.1810  0.1815  0.1824  0.1817  0.1819  0.1817  0.0005  \n",
      "Fit time          38.41   38.77   38.67   39.56   38.67   38.82   0.39    \n",
      "Test time         0.55    0.67    0.68    0.55    0.68    0.63    0.06    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.29031376, 0.29056225, 0.2913779 , 0.29001904, 0.29127553]),\n",
       " 'test_mae': array([0.18099809, 0.18145941, 0.18236461, 0.18169389, 0.18189709]),\n",
       " 'fit_time': (38.40881538391113,\n",
       "  38.77242612838745,\n",
       "  38.66944980621338,\n",
       "  39.56117534637451,\n",
       "  38.671761989593506),\n",
       " 'test_time': (0.5510618686676025,\n",
       "  0.669342041015625,\n",
       "  0.6794090270996094,\n",
       "  0.5486891269683838,\n",
       "  0.676823616027832)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = Reader(rating_scale=(0, 1))\n",
    "data = Dataset.load_from_df(wals_ratings, reader)\n",
    "algo = SVD(n_factors=300)\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(0, 1))\n",
    "\n",
    "trainset = Dataset.load_from_df(wals_ratings, reader).build_full_trainset()\n",
    "#testset = Dataset.load_from_df(testset, reader).build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7f3c7230bcc0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = SVD(n_factors=300)\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for ix, row in wals_ratings_null.iterrows():\n",
    "    predictions.append(algo.predict(row.wals_code, row.col_name).est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krivas/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "wals_ratings_null['feature'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.pivot_table(pd.concat((wals_ratings_null, wals_ratings), axis=0), values='feature', index=['wals_code'],\n",
    "                         columns=['col_name'], aggfunc=np.sum)\n",
    "temp = temp.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "wals_final = pd.DataFrame()\n",
    "wals_final['wals_code'] = temp['wals_code']\n",
    "for col in list(cols_null.keys()):\n",
    "    group_col = [temp_col for temp_col in temp.columns if temp_col.startswith(col)]\n",
    "    wals_final[col] = temp[group_col].idxmax(axis=1).str.replace(col, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "wals_final = pd.concat((wals_final, wals_target), axis=1)\n",
    "wals_final = wals_final[wals_final['wals_code'].notnull()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "wals_final.to_csv('wals_without_null.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wals_final['Status from Glotto'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wals_final = wals_final.replace({'safe': 0,\n",
    "                                'definitely endangered': 1,\n",
    "                                'vulnerable': 1,\n",
    "                                'critically endangered': 1,\n",
    "                                'severely endangered': 1,\n",
    "                                'extinct': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = wals_final.drop('wals_code', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "wals = wals.replace({'safe': 0,\n",
    "                                'definitely endangered': 1,\n",
    "                                'vulnerable': 1,\n",
    "                                'critically endangered': 1,\n",
    "                                'severely endangered': 1,\n",
    "                                'extinct': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = wals.drop('wals_code', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "cat_cols = [col for col in train.select_dtypes(include=['object']).columns]\n",
    "for col in cat_cols:\n",
    "    train[col] = train[col].fillna(train[col].mode()[0])\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(train[col])\n",
    "    train[col] = le.transform(train[col]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(trn_aucs, val_aucs):\n",
    "    train_auc, train_intconf = np.mean(trn_aucs), 2 * np.std(trn_aucs)\n",
    "    val_auc, val_intconf = np.mean(val_aucs), 2 * np.std(val_aucs)\n",
    "    \n",
    "    train_gini, val_gini = (train_auc - 0.5) * 2, (val_auc - 0.5) * 2\n",
    "    train_gini_intconf, val_gini_intconf = train_intconf * 2, val_intconf * 2\n",
    "    \n",
    "    print(f'Train AUC: {100*train_auc:.2f} +/- {100*train_intconf:.2f} | '\n",
    "          f'Val AUC: {100*val_auc:.2f} +/- {100*val_intconf:.2f} | '\n",
    "          f'Train Gini: {100*train_gini:.2f} +/- {100*train_gini_intconf:.2f} | '\n",
    "          f'Val Gini: {100*val_gini:.2f} +/- {100*val_gini_intconf:.2f}')  \n",
    "    return np.mean(trn_aucs), np.mean(val_aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def test_lgbm(lgbm, X, y, kfolds, cat_features, params, num_rounds=1000):\n",
    "    trn_aucs, val_aucs, trn_f1, val_f1 = [], [], [], []\n",
    "    y_pred = np.zeros(len(X))\n",
    "    models = []\n",
    "    evals_result = []\n",
    "    for trn_idx, val_idx in kfolds.split(X, y):\n",
    "        eval_result = {}\n",
    "        X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "        X_trn, y_trn = X.iloc[trn_idx], y.iloc[trn_idx]\n",
    "        dtrn = lgbm.Dataset(X_trn, y_trn)\n",
    "        dval = lgbm.Dataset(X_val, y_val)\n",
    "        bst = lgbm.train(params, dtrn, num_rounds, [dval],\n",
    "                  early_stopping_rounds=30, #feval=lgb_f1_score, \n",
    "                         evals_result=eval_result,\n",
    "                  verbose_eval=False)\n",
    "        evals_result.append(eval_result)\n",
    "        y_trn_pred = bst.predict(X_trn)\n",
    "        y_val_pred = bst.predict(X_val)\n",
    "        trn_aucs.append(roc_auc_score(y_trn, y_trn_pred))\n",
    "        val_aucs.append(roc_auc_score(y_val, y_val_pred))\n",
    "        \n",
    "        print(f'No. estimators: {bst.best_iteration} | '\n",
    "              f'Train AUC: {100*trn_aucs[-1]:.2f} | '\n",
    "              f'Val AUC: {100*val_aucs[-1]:.2f} | '\n",
    "              f'Train Gini: {(100*trn_aucs[-1]-50)*2:.2f} | '\n",
    "              f'Val Gini: {(100*val_aucs[-1]-50)*2:.2f} | ')\n",
    "        \n",
    "        y_pred[val_idx] = y_val_pred\n",
    "        \n",
    "        models.append(bst)\n",
    "        \n",
    "    print()\n",
    "    print_results(trn_aucs, val_aucs)\n",
    "    print()\n",
    "    return y_pred, models, evals_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. estimators: 39 | Train AUC: 95.73 | Val AUC: 69.26 | Train Gini: 91.46 | Val Gini: 38.53 | \n",
      "No. estimators: 25 | Train AUC: 92.52 | Val AUC: 70.58 | Train Gini: 85.04 | Val Gini: 41.16 | \n",
      "No. estimators: 14 | Train AUC: 90.53 | Val AUC: 58.37 | Train Gini: 81.05 | Val Gini: 16.73 | \n",
      "No. estimators: 31 | Train AUC: 93.20 | Val AUC: 68.49 | Train Gini: 86.39 | Val Gini: 36.99 | \n",
      "No. estimators: 20 | Train AUC: 91.85 | Val AUC: 63.47 | Train Gini: 83.69 | Val Gini: 26.95 | \n",
      "No. estimators: 5 | Train AUC: 82.97 | Val AUC: 60.89 | Train Gini: 65.95 | Val Gini: 21.78 | \n",
      "No. estimators: 20 | Train AUC: 92.32 | Val AUC: 65.68 | Train Gini: 84.64 | Val Gini: 31.36 | \n",
      "No. estimators: 7 | Train AUC: 84.75 | Val AUC: 58.19 | Train Gini: 69.51 | Val Gini: 16.38 | \n",
      "\n",
      "Train AUC: 90.48 +/- 8.17 | Val AUC: 64.37 +/- 9.18 | Train Gini: 80.97 +/- 16.34 | Val Gini: 28.73 +/- 18.35\n",
      "\n",
      "CPU times: user 17.2 s, sys: 24 ms, total: 17.2 s\n",
      "Wall time: 1.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import lightgbm\n",
    "\n",
    "X_train = train.drop('Status from Glotto', axis=1)\n",
    "y_train = train['Status from Glotto']\n",
    "skfolds = StratifiedKFold(n_splits=8, random_state=42, shuffle=True)\n",
    "params = {'objective':'binary', 'gpu_device_id': '1', 'max_depth':7}\n",
    "y_pred, models, evals = test_lgbm(lightgbm, X_train, y_train, skfolds, [], params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. estimators: 102 | Train AUC: 90.14 | Val AUC: 75.17 | Train Gini: 80.28 | Val Gini: 50.35 | \n",
      "No. estimators: 72 | Train AUC: 88.03 | Val AUC: 74.12 | Train Gini: 76.06 | Val Gini: 48.23 | \n",
      "No. estimators: 123 | Train AUC: 90.62 | Val AUC: 74.45 | Train Gini: 81.25 | Val Gini: 48.91 | \n",
      "No. estimators: 93 | Train AUC: 89.59 | Val AUC: 74.05 | Train Gini: 79.18 | Val Gini: 48.10 | \n",
      "No. estimators: 104 | Train AUC: 90.39 | Val AUC: 73.40 | Train Gini: 80.78 | Val Gini: 46.81 | \n",
      "No. estimators: 68 | Train AUC: 87.58 | Val AUC: 74.96 | Train Gini: 75.17 | Val Gini: 49.93 | \n",
      "No. estimators: 17 | Train AUC: 81.07 | Val AUC: 67.11 | Train Gini: 62.14 | Val Gini: 34.22 | \n",
      "No. estimators: 107 | Train AUC: 90.26 | Val AUC: 75.91 | Train Gini: 80.53 | Val Gini: 51.82 | \n",
      "\n",
      "Train AUC: 88.46 +/- 5.97 | Val AUC: 73.65 +/- 5.15 | Train Gini: 76.92 +/- 11.94 | Val Gini: 47.29 +/- 10.29\n",
      "\n",
      "CPU times: user 20.5 s, sys: 8 ms, total: 20.5 s\n",
      "Wall time: 1.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import lightgbm\n",
    "\n",
    "X_train = train.drop('Status from Glotto', axis=1)\n",
    "y_train = train['Status from Glotto']\n",
    "skfolds = StratifiedKFold(n_splits=8, random_state=42, shuffle=True)\n",
    "params = {'objective':'binary', 'gpu_device_id': '1', 'max_depth':7}\n",
    "y_pred, models, evals = test_lgbm(lightgbm, X_train, y_train, skfolds, [], params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
